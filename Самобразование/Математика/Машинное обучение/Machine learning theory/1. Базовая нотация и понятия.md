---

# Формальная модель обучения с учителем

* **Вход алгоритма МО (Learner's input)**:
	* **Область определения (Domain Set)**. Множество $\mathbb{X}$ всех объектов предметной области, подлежащей разметке искомой функцией $f: \mathbb{X} \rightarrow \mathbb{Y}$. По-сути, генеральная совокупность всех объектов предметной области.
	* **Область значений, множество меток (Label set)**. Множество $\mathbb{Y}$ всех возможных ответов для объектов из $\mathbb{X}$.
	* **Тренировочные данные (Training Data)**. Множество пар объектов-ответов: $S = \{ (x_1, y_1), \dots, (x_m, y_m) \}$, где $\forall x_i \in \mathbb{X}$ и $\forall y_i \in \mathbb{Y}$. Другими словами, $S \subseteq \mathbb{X} \times \mathbb{Y}$.
* **Результат алгоритма МО (Learner Output)**. Результатом работы алгоритма МО является некоторая функция $h: \mathbb{X} \rightarrow \mathbb{Y}$, стремящаяся приблизить неизвестную зависимость $f: \mathbb{X} \rightarrow \mathbb{Y}$. Такая функция часто называется предиктором (*predictor*), гипотезой (*hypothesis*) или классификатором (*classifier*). Алгоритм МО соотственно: $A: \mathbb{X} \times \mathbb{Y} \rightarrow (h: \mathbb{X} \rightarrow \mathbb{Y})$.
* **Модель генерации данных**. Предполагается, что есть некоторое распределение значений $\mathbb{D}$ на множестве $\mathbb{X} \times \mathbb{Y}$. Предполагается что множество $S$ получается из этой модели. При чем можно встать на одну из сторон:
	1. Существует некоторая неизвестная функция $f: \mathbb{X} \rightarrow \mathbb{Y}$ и это именно функция, то есть она каждому объекту области определения сопоставит только один товет ответ из области значений.
	2. Такой функции не существует и одному и тому же $x \in \mathbb{X}$ может соответствовать несколько различных $y \in \mathbb{Y}$. Тогда можно говорить о распределении вероятностей $P(Y=y_i|X=x_i)$.
* **Оценка успешности алгоритма обучения (Loss Function)**. Функция, используемая для численной оценки того, насколько хорошо найденная гипотеза $h: \mathbb{X} \rightarrow \mathbb{Y}$ смогла подогнаться под данные из $S$. Оценка ошибки классификатора [^1]:

$$ \mathbb{L_{\mathbb{D},f}}(h) \stackrel{\text{def}}{=} \mathbb{P}_{x \sim \mathbb{D}}[h(x) \ne f(x)] \stackrel{\text{def}}{=} \mathbb{D}(\{x : h(x) \ne f(x)\}) $$

[^1]: В данной книге $\mathbb{D}({x: p(x)})$ означает вероятность наблюдения множества иксов, полученных моделью генерации $\mathbb{D}$ и отфильтрованных предикатом $p: \mathbb{X} \rightarrow \{0, 1\}$.

# Минимизация эмпирического риска (ERM)
#ml/erm

ERM - это принцип