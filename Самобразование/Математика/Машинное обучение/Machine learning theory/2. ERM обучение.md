#ml/erm

---

* Особенность метрики $\mathbb{L}_{\mathbb{D}, f}(h)$ #ml/general_loss в том, что она опирается на неизвестное распределение $\mathbb{D}: X \times Y \rightarrow [0, 1]$. Все что доступно - это выборка $S = \{(x, y): x \sim \mathbb{D},\ y = f(x)\}$ или, в случае если предположение о существовании $f: X \rightarrow Y$ не используется, то $S \subset (X \times Y) \sim \mathbb{D}$. 
* Здесь и далее мы будем опираться на существование функции $f$  и, более того, мы предполагаем важное допущение #ml/terms/reliability_assumption:
$$f \in H$$
	то есть то, что данная функция лежит в пространстве гипотез из которых выбирается гипотеза для классификации (регрессии).

* Таким образом, мы можем определить только эмпирический риск (empirical risk #ml/tems/empirical_risk):
$$ \mathbb{L}_{S}(h) = \frac{|\{x : x \in S, h(x) \neq f(x)\}|}{|S|} $$
* Если не ограничивать $H$ никак, то при $|H| = \infty$ алгоритм машинного обучения всегда будет переобучаться, то есть всегда будет возможность найти такое $h$, что $\mathbb{L_{S}(h)} = 0$ и при этом $\mathbb{L_{\mathbb{D},d}}(h) > 0$